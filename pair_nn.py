import os.path as osp
import argparse
from sklearn.neighbors import NearestNeighbors
import torch
import json
import operator
from lib import DATASETS


def check_nn_map_file(nn_map_file, real_dataset_image_filenames):
    """Check if existing nn map file contains the same real images' filenames.

    Args:
        nn_map_file (str): nn map file
        real_dataset_image_filenames (list): list of real images' filenames

    Returns:
        exists (bool): whether the nn map file exists and contains the correct real images' filenames
    """
    exists = osp.exists(nn_map_file)
    if not exists:
        return exists

    with open(nn_map_file) as f:
        nn_map = json.load(f)
    exists = set(nn_map.keys()) == set(real_dataset_image_filenames)

    return exists


def main():
    """A script for finding the Nearest Neighbor (NN) of each sample in a given real dataset from a pool of fake images
    (as generated by `create_fake_dataset.py`). The NNs will be found in all available features spaces (CLIP [1] and/or
    OpenCLIP [X] and/or FaRL [2] and/or DINO [3] and/or DINOv2 [Y] ArcFace [4] and/or DECA [5]) depending on their
    availability in the given real and fake datasets.

    For any given real dataset, a file that contains the map between the real images and the fake NNs will be stored
    under the fake dataset's directory.

    Options:
        -v, --verbose       : set verbose mode on
        --fake-dataset-root : set the fake dataset's root directory (as generated by `create_fake_dataset.py` under
                              datasets/)
        --algorithm         : set algorithm used to compute the nearest neighbors ('auto', 'ball_tree', 'kd_tree',
                              'brute')
        --metric            : set metric to use for distance computation
        --cuda              : use CUDA (default)
        --no-cuda           : do not use CUDA

    References:
        [1] Radford, Alec, et al. "Learning transferable visual models from natural language supervision."
            International Conference on Machine Learning. PMLR, 2021.
        [X] Cherti, Mehdi, et al. "Reproducible scaling laws for contrastive language-image learning." Proceedings of
            the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2023.
        [2] Zheng, Yinglin, et al. "General Facial Representation Learning in a Visual-Linguistic Manner."
            Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2022.
        [3] Caron, Mathilde, et al. "Emerging properties in self-supervised vision transformers." Proceedings of the
            IEEE/CVF International Conference on Computer Vision. 2021.
        [Y] Oquab, Maxime, et al. "Dinov2: Learning robust visual features without supervision."
            arXiv preprint arXiv:2304.07193 (2023).
        [4] Deng, Jiankang, et al. "ArcFace: Additive angular margin loss for deep face recognition." Proceedings of
            the IEEE/CVF conference on computer vision and pattern recognition. 2019.
        [5] Yao Feng, Haiwen Feng, Michael J Black, and Timo Bolkart. Learning an animatable detailed 3d face model from
            in-the-wild images. ACM Transactions on Graphics (TOG), 2021

    """
    parser = argparse.ArgumentParser(
        description="Pair each image of a given real dataset with an image of a given fake dataset")
    parser.add_argument('-v', '--verbose', action='store_true', help="verbose mode on")
    parser.add_argument('--real-dataset', type=str, required=True, choices=DATASETS.keys(), help="real dataset")
    parser.add_argument('--real-dataset-root', type=str, help="set real dataset root directory")
    parser.add_argument('--fake-dataset-root', type=str,
                        help="set the fake dataset's root directory "
                             "(as generated by `create_fake_dataset.py` under datasets/)")
    parser.add_argument('-K', type=int, default=5, help="set number K of NNs")
    parser.add_argument('--algorithm', default='all', choices=('auto', 'ball_tree', 'kd_tree', 'brute', 'all'),
                        help="set algorithm used to compute the nearest neighbors")
    parser.add_argument('--metric', type=str, default='all', choices=('euclidean', 'cosine', 'all'),
                        help="metric to use for distance computation")
    parser.add_argument('--cuda', dest='cuda', action='store_true', help="use CUDA during training")
    parser.add_argument('--no-cuda', dest='cuda', action='store_false', help="do NOT use CUDA during training")
    parser.set_defaults(cuda=True)

    # Parse given arguments
    args = parser.parse_args()

    # Check if pose features (landmarks and angles) have been extracted for the real dataset (pose features for the
    # fake dataset should have been extracted upon the creation of the fake dataset using `create_fake_dataset.py`)
    for f in ['image_filenames.txt', 'deca_landmarks.pt', 'deca_angles.pt']:
        if not osp.isfile(osp.join(args.real_dataset_root, 'features', f)):
            raise FileNotFoundError("Pose features files not found for the given real dataset: {}. "
                                    "Please create it using `extract_features.py`".format(f))

    # Check if given fake dataset exists
    if not osp.isdir(args.fake_dataset_root):
        raise NotADirectoryError("Invalid fake dataset root directory --  "
                                 "Create a fake dataset using `create_fake_dataset.py`")

    # Choose NN algorithms
    NN_ALGORITHMS = [args.algorithm]
    if args.algorithm == 'all':
        NN_ALGORITHMS = ['auto', 'ball_tree', 'kd_tree', 'brute']

    NN_METRICS = [args.metric]
    if args.metric == 'all':
        NN_METRICS = ['euclidean', 'cosine']

    ####################################################################################################################
    ##                                                                                                                ##
    ##                                            [ Real Dataset Features ]                                           ##
    ##                                                                                                                ##
    ####################################################################################################################
    real_dataset_features_dir = osp.join(args.real_dataset_root, 'features')
    if not osp.isdir(real_dataset_features_dir):
        raise NotADirectoryError(
            "Directory of real dataset features ({}) not found -- use `extract_features.py` to create it.".format(
                real_dataset_features_dir))

    if args.verbose:
        print("#. Real dataset features directory: {}".format(real_dataset_features_dir))

    # Get real dataset image filenames
    with open(osp.join(real_dataset_features_dir, 'image_filenames.txt')) as f:
        content_list = f.readlines()
    real_dataset_image_filenames = [x.strip() for x in content_list]

    if args.verbose:
        print("  \\__real_dataset_image_filenames: {}".format(len(real_dataset_image_filenames)))

    # === CLIP features ===
    clip_real_features = None
    clip_real_features_file = osp.join(real_dataset_features_dir, 'clip_features.pt')
    use_clip = osp.exists(clip_real_features_file)
    if use_clip:
        clip_real_features = torch.load(clip_real_features_file).numpy()
        if args.verbose:
            print("  \\__CLIP features: {}".format(clip_real_features.shape))

    # === OpenCLIP features ===
    openclip_real_features = None
    openclip_real_features_file = osp.join(real_dataset_features_dir, 'openclip_features.pt')
    use_openclip = osp.exists(openclip_real_features_file)
    if use_openclip:
        openclip_real_features = torch.load(openclip_real_features_file).numpy()
        if args.verbose:
            print("  \\__OpenCLIP features: {}".format(openclip_real_features.shape))

    # === FaRL features ===
    farl_real_features = None
    farl_real_features_file = osp.join(real_dataset_features_dir, 'farl_features.pt')
    use_farl = osp.exists(farl_real_features_file)
    if use_farl:
        farl_real_features = torch.load(farl_real_features_file).numpy()
        if args.verbose:
            print("  \\__FaRL features: {}".format(farl_real_features.shape))

    # === DINO features ===
    dino_real_features = None
    dino_real_features_file = osp.join(real_dataset_features_dir, 'dino_features.pt')
    use_dino = osp.exists(dino_real_features_file)
    if use_dino:
        dino_real_features = torch.load(dino_real_features_file).numpy()
        if args.verbose:
            print("  \\__DINO features: {}".format(dino_real_features.shape))

    # === DINOv2 features ===
    dinov2_real_features = None
    dinov2_real_features_file = osp.join(real_dataset_features_dir, 'dinov2_features.pt')
    use_dinov2 = osp.exists(dinov2_real_features_file)
    if use_dinov2:
        dinov2_real_features = torch.load(dinov2_real_features_file).numpy()
        if args.verbose:
            print("  \\__DINOv2 features: {}".format(dinov2_real_features.shape))

    # === ArcFace features ===
    arcface_real_features = None
    arcface_real_features_file = osp.join(real_dataset_features_dir, 'arcface_features.pt')
    use_arcface = osp.exists(arcface_real_features_file)
    if use_arcface:
        arcface_real_features = torch.load(arcface_real_features_file).numpy()
        if args.verbose:
            print("  \\__ArcFace features: {}".format(arcface_real_features.shape))

    # === DECA landmarks and angles ===
    deca_real_landmarks = None
    deca_real_landmarks_file = osp.join(real_dataset_features_dir, 'deca_landmarks.pt')
    use_deca_landmarks = osp.exists(deca_real_landmarks_file)
    if use_deca_landmarks:
        deca_real_landmarks = torch.load(deca_real_landmarks_file).numpy()
        if args.verbose:
            print("  \\__DECA landmarks: {}".format(deca_real_landmarks.shape))

    deca_real_angles = None
    deca_real_angles_file = osp.join(real_dataset_features_dir, 'deca_angles.pt')
    use_deca_angles = osp.exists(deca_real_angles_file)
    if use_deca_angles:
        deca_real_angles = torch.load(deca_real_angles_file).numpy()
        if args.verbose:
            print("  \\__DECA angles: {}".format(deca_real_angles.shape))

    ####################################################################################################################
    ##                                                                                                                ##
    ##                                            [ Fake Dataset Features ]                                           ##
    ##                                                                                                                ##
    ####################################################################################################################
    fake_dataset_pose_features_dir = args.fake_dataset_root
    if args.verbose:
        print("#. Fake dataset features directory: {}".format(fake_dataset_pose_features_dir))

    # # Get fake dataset image filenames
    with open(osp.join(fake_dataset_pose_features_dir, 'latent_code_hashes.txt')) as f:
        content_list = f.readlines()
    fake_dataset_image_filenames = [x.strip() for x in content_list]
    if args.verbose:
        print("  \\__fake_dataset_image_filenames: {}".format(len(fake_dataset_image_filenames)))

    # === CLIP features ===
    clip_fake_features_file = osp.join(args.fake_dataset_root, 'clip_features.pt')
    clip_fake_features = torch.load(clip_fake_features_file).numpy()
    if args.verbose:
        print("  \\__CLIP features: {}".format(clip_fake_features.shape))

    # === OpenCLIP features ===
    openclip_fake_features_file = osp.join(args.fake_dataset_root, 'openclip_features.pt')
    openclip_fake_features = torch.load(openclip_fake_features_file).numpy()
    if args.verbose:
        print("  \\__OpenCLIP features: {}".format(openclip_fake_features.shape))

    # === FaRL features ===
    farl_fake_features_file = osp.join(args.fake_dataset_root, 'farl_features.pt')
    farl_fake_features = torch.load(farl_fake_features_file).numpy()
    if args.verbose:
        print("  \\__FaRL features: {}".format(farl_fake_features.shape))

    # === DINO features ===
    dino_fake_features_file = osp.join(args.fake_dataset_root, 'dino_features.pt')
    dino_fake_features = torch.load(dino_fake_features_file).numpy()
    if args.verbose:
        print("  \\__DINO features: {}".format(dino_fake_features.shape))

    # === DINOv2 features ===
    dinov2_fake_features_file = osp.join(args.fake_dataset_root, 'dinov2_features.pt')
    dinov2_fake_features = torch.load(dinov2_fake_features_file).numpy()
    if args.verbose:
        print("  \\__DINOv2 features: {}".format(dinov2_fake_features.shape))

    # === ArcFace features ===
    arcface_fake_features_file = osp.join(args.fake_dataset_root, 'arcface_features.pt')
    arcface_fake_features = torch.load(arcface_fake_features_file).numpy()
    if args.verbose:
        print("  \\__ArcFace features: {}".format(arcface_fake_features.shape))

    # === DECA landmarks ===
    deca_landmarks_fake_features_file = osp.join(args.fake_dataset_root, 'deca_landmarks.pt')
    deca_landmarks_fake_features = torch.load(deca_landmarks_fake_features_file).numpy()
    if args.verbose:
        print("  \\__DECA landmarks: {}".format(deca_landmarks_fake_features.shape))

    # === DECA angles ===
    deca_angles_fake_features_file = osp.join(args.fake_dataset_root, 'deca_angles.pt')
    deca_angles_fake_features = torch.load(deca_angles_fake_features_file).numpy()
    if args.verbose:
        print("  \\__DECA angles: {}".format(deca_angles_fake_features.shape))

    ####################################################################################################################
    ##                                                                                                                ##
    ##                                                 [ NN pairing ]                                                 ##
    ##                                                                                                                ##
    ####################################################################################################################
    if args.verbose:
        print("#. Finding NNs for the following algorithms and metrics:")
        print("  \\__NN algorithms : {}".format(NN_ALGORITHMS))
        print("  \\__NN metrics    : {}".format(NN_METRICS))
        print("#. Process...")

    for nn_metric in NN_METRICS:
        for nn_algorithm in NN_ALGORITHMS:

            print("  \\__.(metric, algorithm) = ({}, {})".format(nn_metric, nn_algorithm))

            if ((nn_metric == 'cosine') and (nn_algorithm == 'ball_tree')) or \
                    ((nn_metric == 'cosine') and (nn_algorithm == 'kd_tree')):
                print("      \\__.Invalid combination -- Abort!")
                continue

            ############################################################################################################
            ##                                           [ Fit NN models ]                                            ##
            ############################################################################################################

            # === CLIP ===
            clip_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_clip_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_clip = osp.exists(clip_fake_features_file) and \
                use_clip and \
                (not check_nn_map_file(clip_nn_map_file, real_dataset_image_filenames))

            nn_model_clip = None
            if use_clip:
                if args.verbose:
                    print("      \\__Fit CLIP NN model...", end="")
                nn_model_clip = NearestNeighbors(n_neighbors=args.K,
                                                 algorithm=nn_algorithm,
                                                 metric=nn_metric
                                                 ).fit(clip_fake_features)
                if args.verbose:
                    print("Done!")

            # === OpenCLIP ===
            openclip_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_openclip_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_openclip = osp.exists(openclip_fake_features_file) and use_openclip and (
                not check_nn_map_file(openclip_nn_map_file, real_dataset_image_filenames))

            nn_model_openclip = None
            if use_openclip:
                if args.verbose:
                    print("      \\__Fit OpenCLIP NN model...", end="")
                nn_model_openclip = NearestNeighbors(n_neighbors=args.K,
                                                     algorithm=nn_algorithm,
                                                     metric=nn_metric
                                                     ).fit(openclip_fake_features)
                if args.verbose:
                    print("Done!")

            # === FaRL ===
            farl_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_farl_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_farl = osp.exists(farl_fake_features_file) and \
                use_farl and \
                (not check_nn_map_file(farl_nn_map_file, real_dataset_image_filenames))

            nn_model_farl = None
            if use_farl:
                if args.verbose:
                    print("      \\__Fit FaRL NN model...", end="")

                nn_model_farl = NearestNeighbors(n_neighbors=args.K,
                                                 algorithm=nn_algorithm,
                                                 metric=nn_metric
                                                 ).fit(farl_fake_features)
                if args.verbose:
                    print("Done!")

            # === DINO ===
            dino_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_dino_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_dino = osp.exists(dino_fake_features_file) and \
                use_dino and \
                (not check_nn_map_file(dino_nn_map_file, real_dataset_image_filenames))

            nn_model_dino = None
            if use_dino:
                if args.verbose:
                    print("      \\__Fit DINO NN model...", end="")

                nn_model_dino = NearestNeighbors(n_neighbors=args.K,
                                                 algorithm=nn_algorithm,
                                                 metric=nn_metric
                                                 ).fit(dino_fake_features)
                if args.verbose:
                    print("Done!")

            # === DINOv2 ===
            dinov2_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_dinov2_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_dinov2 = osp.exists(dinov2_fake_features_file) and use_dinov2 and (
                not check_nn_map_file(dinov2_nn_map_file, real_dataset_image_filenames))

            nn_model_dinov2 = None
            if use_dinov2:
                if args.verbose:
                    print("      \\__Fit DINOv2 NN model...", end="")

                nn_model_dinov2 = NearestNeighbors(n_neighbors=args.K,
                                                   algorithm=nn_algorithm,
                                                   metric=nn_metric
                                                   ).fit(dinov2_fake_features)
                if args.verbose:
                    print("Done!")

            # === ArcFace ===
            arcface_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_arcface_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_arcface = osp.exists(arcface_fake_features_file) and \
                use_arcface and \
                (not check_nn_map_file(arcface_nn_map_file, real_dataset_image_filenames))

            nn_model_arcface = None
            if use_arcface:
                if args.verbose:
                    print("      \\__Fit ArcFace NN model...", end="")

                nn_model_arcface = NearestNeighbors(n_neighbors=args.K,
                                                    algorithm=nn_algorithm,
                                                    metric=nn_metric
                                                    ).fit(arcface_fake_features)
                if args.verbose:
                    print("Done!")

            # === DECA landmarks ===
            deca_landmarks_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_deca-landmarks_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_deca_landmarks = osp.exists(deca_landmarks_fake_features_file) and use_deca_landmarks and (
                not check_nn_map_file(deca_landmarks_nn_map_file, real_dataset_image_filenames))

            nn_model_deca_landmarks = None
            if use_deca_landmarks:
                if args.verbose:
                    print("      \\__Fit DECA (landmarks) NN model...", end="")

                nn_model_deca_landmarks = NearestNeighbors(n_neighbors=args.K,
                                                           algorithm=nn_algorithm,
                                                           metric=nn_metric
                                                           ).fit(deca_landmarks_fake_features)
                if args.verbose:
                    print("Done!")

            # === DECA angles ===
            deca_angles_nn_map_file = osp.join(args.fake_dataset_root, 'nn_map_deca-angles_{}_{}.json'.format(
                nn_algorithm, nn_metric))

            use_deca_angles = osp.exists(deca_angles_fake_features_file) and use_deca_angles and (
                not check_nn_map_file(deca_angles_nn_map_file, real_dataset_image_filenames))

            nn_model_deca_angles = None
            if use_deca_angles:
                if args.verbose:
                    print("      \\__Fit DECA (angles) NN model...", end="")

                nn_model_deca_angles = NearestNeighbors(n_neighbors=args.K,
                                                        algorithm=nn_algorithm,
                                                        metric=nn_metric
                                                        ).fit(deca_angles_fake_features)
                if args.verbose:
                    print("Done!")

            ############################################################################################################
            ##                                              [ Find NNs ]                                              ##
            ############################################################################################################
            if args.verbose:
                print("      \\__.Find NNs...")

            # === CLIP ===
            if use_clip:
                if args.verbose:
                    print("          \\__CLIP...", end="")
                _, indices = nn_model_clip.kneighbors(clip_real_features)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(clip_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === OpenCLIP ===
            if use_openclip:
                if args.verbose:
                    print("          \\__OpenCLIP...", end="")
                _, indices = nn_model_openclip.kneighbors(openclip_real_features)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(openclip_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === FaRL ===
            if use_farl:
                if args.verbose:
                    print("          \\__FaRL...", end="")
                _, indices = nn_model_farl.kneighbors(farl_real_features)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]:
                #                    fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(farl_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === DINO ===
            if use_dino:
                if args.verbose:
                    print("          \\__DINO...", end="")
                _, indices = nn_model_dino.kneighbors(dino_real_features)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(dino_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === DINOv2 ===
            if use_dinov2:
                if args.verbose:
                    print("          \\__DINOv2...", end="")
                _, indices = nn_model_dinov2.kneighbors(dinov2_real_features)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(dinov2_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === ArcFace  ===
            if use_arcface:
                if args.verbose:
                    print("          \\__ArcFace...", end="")
                _, indices = nn_model_arcface.kneighbors(arcface_real_features)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(arcface_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === DECA landmarks  ===
            if use_deca_landmarks:
                if args.verbose:
                    print("          \\__DECA landmarks...", end="")
                _, indices = nn_model_deca_landmarks.kneighbors(deca_real_landmarks)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(deca_landmarks_nn_map_file, "w") as f:
                    json.dump(nn_map, f)

            # === DECA angles  ===
            if use_deca_angles:
                if args.verbose:
                    print("          \\__DECA angles...", end="")
                _, indices = nn_model_deca_angles.kneighbors(deca_real_angles)
                if args.verbose:
                    print("Done!")

                # Build NN map dictionary
                nn_map = dict()
                # for i in range(len(real_dataset_image_filenames)):
                #     nn_map.update({real_dataset_image_filenames[i]: fake_dataset_image_filenames[int(indices[i])]})
                for i in range(len(real_dataset_image_filenames)):
                    nn_map.update(
                        {
                            real_dataset_image_filenames[i]:
                                operator.itemgetter(*indices[i].tolist())(fake_dataset_image_filenames)
                        })

                # Save nn map
                with open(deca_angles_nn_map_file, "w") as f:
                    json.dump(nn_map, f)


if __name__ == '__main__':
    main()
